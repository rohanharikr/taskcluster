# Stored Functions
<!-- AUTOGENERATED CONTENT; DO NOT EDIT -->

 * [auth functions](#auth)
   * [`create_client`](#create_client)
   * [`delete_client`](#delete_client)
   * [`expire_clients`](#expire_clients)
   * [`get_client`](#get_client)
   * [`get_clients`](#get_clients)
   * [`get_roles`](#get_roles)
   * [`modify_roles`](#modify_roles)
   * [`update_client`](#update_client)
   * [`update_client_last_used`](#update_client_last_used)
 * [github functions](#github)
   * [`create_github_build`](#create_github_build)
   * [`create_github_check`](#create_github_check)
   * [`delete_github_build`](#delete_github_build)
   * [`get_github_build`](#get_github_build)
   * [`get_github_builds`](#get_github_builds)
   * [`get_github_check_by_task_id`](#get_github_check_by_task_id)
   * [`get_github_integration`](#get_github_integration)
   * [`get_github_integrations`](#get_github_integrations)
   * [`set_github_build_state`](#set_github_build_state)
   * [`upsert_github_integration`](#upsert_github_integration)
 * [hooks functions](#hooks)
   * [`create_hook`](#create_hook)
   * [`create_hooks_queue`](#create_hooks_queue)
   * [`create_last_fire`](#create_last_fire)
   * [`delete_hook`](#delete_hook)
   * [`delete_hooks_queue`](#delete_hooks_queue)
   * [`delete_last_fires`](#delete_last_fires)
   * [`expire_last_fires`](#expire_last_fires)
   * [`get_hook`](#get_hook)
   * [`get_hooks`](#get_hooks)
   * [`get_hooks_queues`](#get_hooks_queues)
   * [`get_last_fire`](#get_last_fire)
   * [`get_last_fires`](#get_last_fires)
   * [`update_hook`](#update_hook)
   * [`update_hooks_queue_bindings`](#update_hooks_queue_bindings)
 * [index functions](#index)
   * [`create_index_namespace`](#create_index_namespace)
   * [`create_indexed_task`](#create_indexed_task)
   * [`expire_index_namespaces`](#expire_index_namespaces)
   * [`expire_indexed_tasks`](#expire_indexed_tasks)
   * [`get_index_namespace`](#get_index_namespace)
   * [`get_index_namespaces`](#get_index_namespaces)
   * [`get_indexed_task`](#get_indexed_task)
   * [`get_indexed_tasks`](#get_indexed_tasks)
   * [`update_index_namespace`](#update_index_namespace)
   * [`update_indexed_task`](#update_indexed_task)
 * [notify functions](#notify)
   * [`add_denylist_address`](#add_denylist_address)
   * [`all_denylist_addresses`](#all_denylist_addresses)
   * [`delete_denylist_address`](#delete_denylist_address)
   * [`exists_denylist_address`](#exists_denylist_address)
 * [purge_cache functions](#purge_cache)
   * [`all_purge_requests`](#all_purge_requests)
   * [`expire_cache_purges`](#expire_cache_purges)
   * [`purge_cache`](#purge_cache)
   * [`purge_requests`](#purge_requests)
 * [queue functions](#queue)
   * [`add_task_dependency`](#add_task_dependency)
   * [`azure_queue_count`](#azure_queue_count)
   * [`azure_queue_delete`](#azure_queue_delete)
   * [`azure_queue_delete_expired`](#azure_queue_delete_expired)
   * [`azure_queue_get`](#azure_queue_get)
   * [`azure_queue_put`](#azure_queue_put)
   * [`azure_queue_update`](#azure_queue_update)
   * [`cancel_task`](#cancel_task)
   * [`check_task_claim`](#check_task_claim)
   * [`claim_task`](#claim_task)
   * [`create_queue_artifact`](#create_queue_artifact)
   * [`create_queue_provisioner`](#create_queue_provisioner)
   * [`create_queue_worker`](#create_queue_worker)
   * [`create_queue_worker_type`](#create_queue_worker_type)
   * [`create_task`](#create_task)
   * [`delete_queue_artifact`](#delete_queue_artifact)
   * [`delete_queue_provisioner`](#delete_queue_provisioner)
   * [`delete_queue_worker_type`](#delete_queue_worker_type)
   * [`ensure_task_group`](#ensure_task_group)
   * [`expire_queue_provisioners`](#expire_queue_provisioners)
   * [`expire_queue_worker_types`](#expire_queue_worker_types)
   * [`expire_queue_workers`](#expire_queue_workers)
   * [`expire_task_dependencies`](#expire_task_dependencies)
   * [`expire_task_groups`](#expire_task_groups)
   * [`expire_tasks`](#expire_tasks)
   * [`get_dependent_tasks`](#get_dependent_tasks)
   * [`get_queue_artifact`](#get_queue_artifact)
   * [`get_queue_artifacts`](#get_queue_artifacts)
   * [`get_queue_provisioner`](#get_queue_provisioner)
   * [`get_queue_provisioners`](#get_queue_provisioners)
   * [`get_queue_worker`](#get_queue_worker)
   * [`get_queue_worker_type`](#get_queue_worker_type)
   * [`get_queue_worker_types`](#get_queue_worker_types)
   * [`get_queue_workers`](#get_queue_workers)
   * [`get_task`](#get_task)
   * [`get_task_group`](#get_task_group)
   * [`get_tasks_by_task_group`](#get_tasks_by_task_group)
   * [`is_task_blocked`](#is_task_blocked)
   * [`is_task_group_active`](#is_task_group_active)
   * [`mark_task_ever_resolved`](#mark_task_ever_resolved)
   * [`reclaim_task`](#reclaim_task)
   * [`remove_task`](#remove_task)
   * [`remove_task_dependency`](#remove_task_dependency)
   * [`rerun_task`](#rerun_task)
   * [`resolve_task`](#resolve_task)
   * [`resolve_task_at_deadline`](#resolve_task_at_deadline)
   * [`satisfy_task_dependency`](#satisfy_task_dependency)
   * [`schedule_task`](#schedule_task)
   * [`update_queue_artifact`](#update_queue_artifact)
   * [`update_queue_provisioner`](#update_queue_provisioner)
   * [`update_queue_worker`](#update_queue_worker)
   * [`update_queue_worker_type`](#update_queue_worker_type)
 * [secrets functions](#secrets)
   * [`delete_secret`](#delete_secret)
   * [`expire_secrets`](#expire_secrets)
   * [`get_secret`](#get_secret)
   * [`get_secrets`](#get_secrets)
   * [`upsert_secret`](#upsert_secret)
 * [web_server functions](#web_server)
   * [`add_github_access_token`](#add_github_access_token)
   * [`create_access_token`](#create_access_token)
   * [`create_authorization_code`](#create_authorization_code)
   * [`expire_access_tokens`](#expire_access_tokens)
   * [`expire_authorization_codes`](#expire_authorization_codes)
   * [`expire_sessions`](#expire_sessions)
   * [`get_access_token`](#get_access_token)
   * [`get_authorization_code`](#get_authorization_code)
   * [`load_github_access_token`](#load_github_access_token)
   * [`session_add`](#session_add)
   * [`session_load`](#session_load)
   * [`session_remove`](#session_remove)
   * [`session_touch`](#session_touch)
 * [worker_manager functions](#worker_manager)
   * [`create_worker`](#create_worker)
   * [`create_worker_pool`](#create_worker_pool)
   * [`create_worker_pool_error`](#create_worker_pool_error)
   * [`delete_worker`](#delete_worker)
   * [`delete_worker_pool`](#delete_worker_pool)
   * [`delete_worker_pool_error`](#delete_worker_pool_error)
   * [`expire_worker_pool_errors`](#expire_worker_pool_errors)
   * [`expire_worker_pools`](#expire_worker_pools)
   * [`expire_workers`](#expire_workers)
   * [`get_worker_2`](#get_worker_2)
   * [`get_worker_pool_error`](#get_worker_pool_error)
   * [`get_worker_pool_errors_for_worker_pool`](#get_worker_pool_errors_for_worker_pool)
   * [`get_worker_pool_with_capacity`](#get_worker_pool_with_capacity)
   * [`get_worker_pools_with_capacity`](#get_worker_pools_with_capacity)
   * [`get_workers`](#get_workers)
   * [`remove_worker_pool_previous_provider_id`](#remove_worker_pool_previous_provider_id)
   * [`update_worker_2`](#update_worker_2)
   * [`update_worker_pool_provider_data`](#update_worker_pool_provider_data)
   * [`update_worker_pool_with_capacity`](#update_worker_pool_with_capacity)

## auth

* [`create_client`](#create_client)
* [`delete_client`](#delete_client)
* [`expire_clients`](#expire_clients)
* [`get_client`](#get_client)
* [`get_clients`](#get_clients)
* [`get_roles`](#get_roles)
* [`modify_roles`](#modify_roles)
* [`update_client`](#update_client)
* [`update_client_last_used`](#update_client_last_used)

### create_client

* *Mode*: write
* *Arguments*:
  * `client_id_in text`
  * `description_in text`
  * `encrypted_access_token_in jsonb`
  * `expires_in timestamptz`
  * `disabled_in boolean`
  * `scopes_in jsonb`
  * `delete_on_expiration_in boolean`
* *Returns*: `void`

Create a new client.  The created and last_.. timestamps are all
initialized to the current time.  If the row exists but scopes,
description, and expires match, disabled is false, and it was created in
the last 15 minutes, then nothing is changed.  Otherwise, a
UNIQUE_VIOLATION is raised.

### delete_client

* *Mode*: write
* *Arguments*:
  * `client_id_in text`
* *Returns*: `void`

Delete the given client.  If the client does not exist, nothing happens.

### expire_clients

* *Mode*: write
* *Arguments*:
* *Returns*: `integer`

Delete all clients with an 'expires' in the past and with 'delete_on_expiration' set.

### get_client

* *Mode*: read
* *Arguments*:
  * `client_id_in text`
* *Returns*: `table`
  * `   client_id text`
  * `  description text`
  * `  encrypted_access_token jsonb`
  * `  expires timestamptz`
  * `  disabled boolean`
  * `  scopes jsonb`
  * `  created timestamptz`
  * `  last_modified timestamptz`
  * `  last_date_used timestamptz`
  * `  last_rotated timestamptz`
  * `  delete_on_expiration boolean `

Get a client. Returns an empty set if the client does not exist.

### get_clients

* *Mode*: read
* *Arguments*:
  * `prefix_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `   client_id text`
  * `  description text`
  * `  encrypted_access_token jsonb`
  * `  expires timestamptz`
  * `  disabled boolean`
  * `  scopes jsonb`
  * `  created timestamptz`
  * `  last_modified timestamptz`
  * `  last_date_used timestamptz`
  * `  last_rotated timestamptz`
  * `  delete_on_expiration boolean `

Get clients, ordered by client_id.   If specified, only clients with
client_id beginning with `prefix` are returned.  If the pagination
arguments are both NULL, all rows are returned.  Otherwise, page_size
rows are returned at offset page_offset.

### get_roles

* *Mode*: read
* *Arguments*:
* *Returns*: `table`
  * `role_id text`
  * `scopes jsonb`
  * `created timestamptz`
  * `description text`
  * `last_modified timestamptz`
  * `etag uuid`

Get the full set of roles.  Each result row has an etag, but all such
etags will be the same, representing the etag for the most recent
modification of the table.  Results are sorted by role_id.

### modify_roles

* *Mode*: write
* *Arguments*:
  * `roles_in jsonb`
  * `old_etag_in uuid`
* *Returns*: `void`

Replace the current set of roles entirely with the given set of roles, if the current etag matches the existing etag. 
The role objects are specified with underscore spelling (`role_id`).
If the etag has changed, this returns P0004 signalling that the caller should fetch a fresh set of roles and try again.
If there are no existing roles, then the old etag is not used.

### update_client

* *Mode*: write
* *Arguments*:
  * `client_id_in text`
  * `description_in text`
  * `encrypted_access_token_in jsonb`
  * `expires_in timestamptz`
  * `disabled_in boolean`
  * `scopes_in jsonb`
  * `delete_on_expiration_in boolean`
* *Returns*: `table`
  * `   client_id text`
  * `  description text`
  * `  encrypted_access_token jsonb`
  * `  expires timestamptz`
  * `  disabled boolean`
  * `  scopes jsonb`
  * `  created timestamptz`
  * `  last_modified timestamptz`
  * `  last_date_used timestamptz`
  * `  last_rotated timestamptz`
  * `  delete_on_expiration boolean `

Update an existing client, returning the updated client or, if no such client
exists, an empty set.  This does not implement optimistic concurrency: any non-null
arguments to this function will overwrite existing values.  The last_modified
column is updated automatically, as is last_rotated if the access token is set.

### update_client_last_used

* *Mode*: write
* *Arguments*:
  * `client_id_in text`
* *Returns*: `void`

Indicate that this client has been recently used, updating its last_date_used field.
Does nothing if the client does not exist.

### deprecated methods

* `clients_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `clients_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `clients_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `clients_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `clients_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)

## github

* [`create_github_build`](#create_github_build)
* [`create_github_check`](#create_github_check)
* [`delete_github_build`](#delete_github_build)
* [`get_github_build`](#get_github_build)
* [`get_github_builds`](#get_github_builds)
* [`get_github_check_by_task_id`](#get_github_check_by_task_id)
* [`get_github_integration`](#get_github_integration)
* [`get_github_integrations`](#get_github_integrations)
* [`set_github_build_state`](#set_github_build_state)
* [`upsert_github_integration`](#upsert_github_integration)

### create_github_build

* *Mode*: write
* *Arguments*:
  * `organization_in text`
  * `repository_in text`
  * `sha_in text`
  * `task_group_id_in text`
  * `state_in text`
  * `created_in timestamptz`
  * `updated_in timestamptz`
  * `installation_id_in integer`
  * `event_type_in text`
  * `event_id_in text`
* *Returns*: `void`

Create a new github build.  Raises UNIQUE_VIOLATION if the pool already exists.

### create_github_check

* *Mode*: write
* *Arguments*:
  * `task_group_id_in text`
  * `task_id_in text`
  * `check_suite_id_in text`
  * `check_run_id_in text`
* *Returns*: `void`

Create a single check.

### delete_github_build

* *Mode*: write
* *Arguments*:
  * `task_group_id_in text`
* *Returns*: `void`

Delete a github build.

### get_github_build

* *Mode*: read
* *Arguments*:
  * `task_group_id_in text`
* *Returns*: `table`
  * `organization text`
  * `repository text`
  * `sha text`
  * `task_group_id text`
  * `state text`
  * `created timestamptz`
  * `updated timestamptz`
  * `installation_id integer`
  * `event_type text`
  * `event_id text`
  * `etag uuid`

Get a github build. The returned table will have one or zero rows.

### get_github_builds

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
  * `organization_in text`
  * `repository_in text`
  * `sha_in text`
* *Returns*: `table`
  * `organization text`
  * `repository text`
  * `sha text`
  * `task_group_id text`
  * `state text`
  * `created timestamptz`
  * `updated timestamptz`
  * `installation_id integer`
  * `event_type text`
  * `event_id text`
  * `etag uuid`

Get github builds. 

### get_github_check_by_task_id

* *Mode*: read
* *Arguments*:
  * `task_id_in text`
* *Returns*: `table`
  * `task_group_id text`
  * `task_id text`
  * `check_suite_id text`
  * `check_run_id text`

Get a single check from a task_id.

### get_github_integration

* *Mode*: read
* *Arguments*:
  * `owner_in text`
* *Returns*: `table`
  * `owner text`
  * `installation_id integer`

Get a single integration by owner.

### get_github_integrations

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `owner text`
  * `installation_id integer`

Get a list of integrations.

### set_github_build_state

* *Mode*: write
* *Arguments*:
  * `task_group_id_in text`
  * `state_in text`
* *Returns*: `void`

Only update the state of a build and update the `updated` timestamp

### upsert_github_integration

* *Mode*: write
* *Arguments*:
  * `owner_in text`
  * `installation_id_in integer`
* *Returns*: `void`

Create a single integration.

### deprecated methods

* `taskcluster_check_runs_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `taskcluster_check_runs_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `taskcluster_check_runs_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `taskcluster_check_runs_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `taskcluster_check_runs_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)
* `taskcluster_checks_to_tasks_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `taskcluster_checks_to_tasks_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `taskcluster_checks_to_tasks_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `taskcluster_checks_to_tasks_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `taskcluster_checks_to_tasks_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)
* `taskcluster_integration_owners_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `taskcluster_integration_owners_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `taskcluster_integration_owners_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `taskcluster_integration_owners_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `taskcluster_integration_owners_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)

## hooks

* [`create_hook`](#create_hook)
* [`create_hooks_queue`](#create_hooks_queue)
* [`create_last_fire`](#create_last_fire)
* [`delete_hook`](#delete_hook)
* [`delete_hooks_queue`](#delete_hooks_queue)
* [`delete_last_fires`](#delete_last_fires)
* [`expire_last_fires`](#expire_last_fires)
* [`get_hook`](#get_hook)
* [`get_hooks`](#get_hooks)
* [`get_hooks_queues`](#get_hooks_queues)
* [`get_last_fire`](#get_last_fire)
* [`get_last_fires`](#get_last_fires)
* [`update_hook`](#update_hook)
* [`update_hooks_queue_bindings`](#update_hooks_queue_bindings)

### create_hook

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `metadata_in jsonb`
  * `task_in jsonb`
  * `bindings_in jsonb`
  * `schedule_in jsonb`
  * `encrypted_trigger_token_in jsonb`
  * `encrypted_next_task_id_in jsonb`
  * `next_scheduled_date_in timestamptz`
  * `trigger_schema_in jsonb`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `metadata jsonb`
  * `task jsonb`
  * `bindings jsonb`
  * `schedule jsonb`
  * `encrypted_trigger_token jsonb`
  * `encrypted_next_task_id jsonb`
  * `next_scheduled_date timestamptz`
  * `trigger_schema jsonb`

Create a new hook. Raises UNIQUE_VIOLATION if the artifact already exists.
Returns the newly created hook.

### create_hooks_queue

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `queue_name_in text`
  * `bindings_in jsonb`
* *Returns*: `uuid`

Create a new hooks queue.  Raises UNIQUE_VIOLATION if the hook already exists.

### create_last_fire

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `fired_by_in text`
  * `task_id_in text`
  * `task_create_time_in timestamptz`
  * `result_in text`
  * `error_in text`
* *Returns*: `uuid`

Create a new hook last fire.  Raises UNIQUE_VIOLATION if the hook already exists.

### delete_hook

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
* *Returns*: `void`

Delete a hook.

### delete_hooks_queue

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
* *Returns*: `void`

Delete a hooks queue.

### delete_last_fires

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
* *Returns*: `void`

Delete last fires that match a given `hook_group_id` and `hook_id`.

### expire_last_fires

* *Mode*: write
* *Arguments*:
* *Returns*: `integer`

Expire last fires that are older than a year.
Returns a count of rows that have been deleted.

### get_hook

* *Mode*: read
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `metadata jsonb`
  * `task jsonb`
  * `bindings jsonb`
  * `schedule jsonb`
  * `encrypted_trigger_token jsonb`
  * `encrypted_next_task_id jsonb`
  * `next_scheduled_date timestamptz`
  * `trigger_schema jsonb`

Get a hook. The returned table will have one or zero rows.

### get_hooks

* *Mode*: read
* *Arguments*:
  * `hook_group_id_in text`
  * `next_scheduled_date_in timestamptz`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `metadata jsonb`
  * `task jsonb`
  * `bindings jsonb`
  * `schedule jsonb`
  * `encrypted_trigger_token jsonb`
  * `encrypted_next_task_id jsonb`
  * `next_scheduled_date timestamptz`
  * `trigger_schema jsonb`

Get existing hooks filtered by the optional `hook_group_id`,
ordered by the `hook_group_id` and `hook_id`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_hooks_queues

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `queue_name text`
  * `bindings jsonb`
  * `etag uuid`

Get hooks queues ordered by `hook_group_id` and `hook_id`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_last_fire

* *Mode*: read
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `task_id_in text`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `fired_by text`
  * `task_id text`
  * `task_create_time timestamptz`
  * `result text`
  * `error text`
  * `etag uuid`

Get a hook last fire.

### get_last_fires

* *Mode*: read
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `fired_by text`
  * `task_id text`
  * `task_create_time timestamptz`
  * `result text`
  * `error text`
  * `etag uuid`

Get hooks last fires filtered by the `hook_group_id` and `hook_id` arguments,
ordered by `hook_group_id`, `hook_id`, and  `worker_id`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### update_hook

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `metadata_in jsonb`
  * `task_in jsonb`
  * `bindings_in jsonb`
  * `schedule_in jsonb`
  * `encrypted_trigger_token_in jsonb`
  * `encrypted_next_task_id_in jsonb`
  * `next_scheduled_date_in timestamptz`
  * `trigger_schema_in jsonb`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `metadata jsonb`
  * `task jsonb`
  * `bindings jsonb`
  * `schedule jsonb`
  * `encrypted_trigger_token jsonb`
  * `encrypted_next_task_id jsonb`
  * `next_scheduled_date timestamptz`
  * `trigger_schema jsonb`

Update a queue artifact.
Returns the up-to-date hook row that have the same hook group id and hook id.

### update_hooks_queue_bindings

* *Mode*: write
* *Arguments*:
  * `hook_group_id_in text`
  * `hook_id_in text`
  * `bindings_in jsonb`
* *Returns*: `table`
  * `hook_group_id text`
  * `hook_id text`
  * `queue_name text`
  * `bindings jsonb`
  * `etag uuid`

Update bindings of a hooks queue. If no such queue exists,
the return value is an empty set.

### deprecated methods

* `hooks_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `hooks_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `hooks_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `hooks_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `hooks_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)
* `last_fire_3_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `last_fire_3_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `last_fire_3_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `last_fire_3_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `last_fire_3_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)
* `queues_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `queues_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `queues_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `queues_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `queues_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)

## index

* [`create_index_namespace`](#create_index_namespace)
* [`create_indexed_task`](#create_indexed_task)
* [`expire_index_namespaces`](#expire_index_namespaces)
* [`expire_indexed_tasks`](#expire_indexed_tasks)
* [`get_index_namespace`](#get_index_namespace)
* [`get_index_namespaces`](#get_index_namespaces)
* [`get_indexed_task`](#get_indexed_task)
* [`get_indexed_tasks`](#get_indexed_tasks)
* [`update_index_namespace`](#update_index_namespace)
* [`update_indexed_task`](#update_indexed_task)

### create_index_namespace

* *Mode*: write
* *Arguments*:
  * `parent_in text`
  * `name_in text`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `parent text`
  * `name text`
  * `expires timestamptz`

Create a new namespace. Raises UNIQUE_VIOLATION if the namespace already exists.
Returns the newly created namespace.

### create_indexed_task

* *Mode*: write
* *Arguments*:
  * `namespace_in text`
  * `name_in text`
  * `rank_in integer`
  * `task_id_in text`
  * `data_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `namespace text`
  * `name text`
  * `rank integer`
  * `task_id text`
  * `data jsonb`
  * `expires timestamptz`

Create a new indexed task. Raises UNIQUE_VIOLATION if the indexed task already exists.
Returns the newly created indexed task.

### expire_index_namespaces

* *Mode*: write
* *Arguments*:
* *Returns*: `integer`

Expire index_namespaces that come before the current time.
Returns a count of rows that have been deleted.

### expire_indexed_tasks

* *Mode*: write
* *Arguments*:
* *Returns*: `integer`

Expire indexed tasks that come before the current time.
Returns a count of rows that have been deleted.

### get_index_namespace

* *Mode*: read
* *Arguments*:
  * `parent_in text`
  * `name_in text`
* *Returns*: `table`
  * `parent text`
  * `name text`
  * `expires timestamptz`

Get a namespace. The returned table will have one or zero rows.

### get_index_namespaces

* *Mode*: read
* *Arguments*:
  * `parent_in text`
  * `name_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `parent text`
  * `name text`
  * `expires timestamptz`

Get existing index_namespaces filtered by the optional arguments,
ordered by the `parent` and `name`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_indexed_task

* *Mode*: read
* *Arguments*:
  * `namespace_in text`
  * `name_in text`
* *Returns*: `table`
  * `namespace text`
  * `name text`
  * `rank integer`
  * `task_id text`
  * `data jsonb`
  * `expires timestamptz`

Get an indexed task. The returned table will have one or zero rows.

### get_indexed_tasks

* *Mode*: read
* *Arguments*:
  * `namespace_in text`
  * `name_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `namespace text`
  * `name text`
  * `rank integer`
  * `task_id text`
  * `data jsonb`
  * `expires timestamptz`

Get existing indexed tasks filtered by the optional arguments,
ordered by the `namespace` and `name`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### update_index_namespace

* *Mode*: write
* *Arguments*:
  * `parent_in text`
  * `name_in text`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `parent text`
  * `name text`
  * `expires timestamptz`

Update a namespace.
Returns the up-to-date namespace row that have the same parent and name.
If the row is not found then an exception with code 'P0002' is thrown.

### update_indexed_task

* *Mode*: write
* *Arguments*:
  * `namespace_in text`
  * `name_in text`
  * `rank_in integer`
  * `task_id_in text`
  * `data_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `namespace text`
  * `name text`
  * `rank integer`
  * `task_id text`
  * `data jsonb`
  * `expires timestamptz`

Update an indexed task.
Returns the up-to-date indexed task row that have the same namespace and name.

## notify

* [`add_denylist_address`](#add_denylist_address)
* [`all_denylist_addresses`](#all_denylist_addresses)
* [`delete_denylist_address`](#delete_denylist_address)
* [`exists_denylist_address`](#exists_denylist_address)

### add_denylist_address

* *Mode*: write
* *Arguments*:
  * `notification_type_in text`
  * `notification_address_in text`
* *Returns*: `void`

If the denylist address already exists, this is a no-op. Otherwise, add the denylist
address for the taskcluster-notify service, with a new random etag.

### all_denylist_addresses

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `notification_type text`
  * `notification_address text`

List all denylist addresses for the taskcluster-notify service.

### delete_denylist_address

* *Mode*: write
* *Arguments*:
  * `notification_type_in text`
  * `notification_address_in text`
* *Returns*: `integer`

Delete a denylist address for the taskcluster-notify service.
Returns number of rows deleted (0 or 1).

### exists_denylist_address

* *Mode*: read
* *Arguments*:
  * `notification_type_in text`
  * `notification_address_in text`
* *Returns*: `boolean`

Returns a boolean indicating whether the denylist type/address exists.

## purge_cache

* [`all_purge_requests`](#all_purge_requests)
* [`expire_cache_purges`](#expire_cache_purges)
* [`purge_cache`](#purge_cache)
* [`purge_requests`](#purge_requests)

### all_purge_requests

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `provisioner_id text`
  * `worker_type text`
  * `cache_name text`
  * `before timestamptz`

View all active purge requests.

### expire_cache_purges

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`

Expire cache purges that come before `expires_in`.
Returns a count of rows that have been deleted.

### purge_cache

* *Mode*: write
* *Arguments*:
  * `provisioner_id_in text`
  * `worker_type_in text`
  * `cache_name_in text`
  * `before_in timestamptz`
  * `expires_in timestamptz`
* *Returns*: `void`

Publish a request to purge caches with name `cache_name_in`
on `provisioner_id_in`/`worker_type_in` workers.

### purge_requests

* *Mode*: read
* *Arguments*:
  * `provisioner_id_in text`
  * `worker_type_in text`
* *Returns*: `table`
  * `provisioner_id text`
  * `worker_type text`
  * `cache_name text`
  * `before timestamptz`

List the caches for this `provisioner_id_in`/`worker_type_in`.

## queue

* [`add_task_dependency`](#add_task_dependency)
* [`azure_queue_count`](#azure_queue_count)
* [`azure_queue_delete`](#azure_queue_delete)
* [`azure_queue_delete_expired`](#azure_queue_delete_expired)
* [`azure_queue_get`](#azure_queue_get)
* [`azure_queue_put`](#azure_queue_put)
* [`azure_queue_update`](#azure_queue_update)
* [`cancel_task`](#cancel_task)
* [`check_task_claim`](#check_task_claim)
* [`claim_task`](#claim_task)
* [`create_queue_artifact`](#create_queue_artifact)
* [`create_queue_provisioner`](#create_queue_provisioner)
* [`create_queue_worker`](#create_queue_worker)
* [`create_queue_worker_type`](#create_queue_worker_type)
* [`create_task`](#create_task)
* [`delete_queue_artifact`](#delete_queue_artifact)
* [`delete_queue_provisioner`](#delete_queue_provisioner)
* [`delete_queue_worker_type`](#delete_queue_worker_type)
* [`ensure_task_group`](#ensure_task_group)
* [`expire_queue_provisioners`](#expire_queue_provisioners)
* [`expire_queue_worker_types`](#expire_queue_worker_types)
* [`expire_queue_workers`](#expire_queue_workers)
* [`expire_task_dependencies`](#expire_task_dependencies)
* [`expire_task_groups`](#expire_task_groups)
* [`expire_tasks`](#expire_tasks)
* [`get_dependent_tasks`](#get_dependent_tasks)
* [`get_queue_artifact`](#get_queue_artifact)
* [`get_queue_artifacts`](#get_queue_artifacts)
* [`get_queue_provisioner`](#get_queue_provisioner)
* [`get_queue_provisioners`](#get_queue_provisioners)
* [`get_queue_worker`](#get_queue_worker)
* [`get_queue_worker_type`](#get_queue_worker_type)
* [`get_queue_worker_types`](#get_queue_worker_types)
* [`get_queue_workers`](#get_queue_workers)
* [`get_task`](#get_task)
* [`get_task_group`](#get_task_group)
* [`get_tasks_by_task_group`](#get_tasks_by_task_group)
* [`is_task_blocked`](#is_task_blocked)
* [`is_task_group_active`](#is_task_group_active)
* [`mark_task_ever_resolved`](#mark_task_ever_resolved)
* [`reclaim_task`](#reclaim_task)
* [`remove_task`](#remove_task)
* [`remove_task_dependency`](#remove_task_dependency)
* [`rerun_task`](#rerun_task)
* [`resolve_task`](#resolve_task)
* [`resolve_task_at_deadline`](#resolve_task_at_deadline)
* [`satisfy_task_dependency`](#satisfy_task_dependency)
* [`schedule_task`](#schedule_task)
* [`update_queue_artifact`](#update_queue_artifact)
* [`update_queue_provisioner`](#update_queue_provisioner)
* [`update_queue_worker`](#update_queue_worker)
* [`update_queue_worker_type`](#update_queue_worker_type)

### add_task_dependency

* *Mode*: write
* *Arguments*:
  * `dependent_task_id_in text`
  * `required_task_id_in text`
  * `requires_in task_requires`
  * `expires_in timestamptz`
* *Returns*: `void`

Create an un-satisfied task dependency between the two tasks, with the given
requirement style and expiration.  If the dependency already exists, nothing
happens.

### azure_queue_count

* *Mode*: read
* *Arguments*:
  * `queue_name text`
* *Returns*: `integer`

Count non-expired messages in the named queue.


### azure_queue_delete

* *Mode*: write
* *Arguments*:
  * `queue_name text`
  * `message_id uuid`
  * `pop_receipt uuid`
* *Returns*: `void`

Delete the message identified by the given `queue_name`, `message_id` and
`pop_receipt`.


### azure_queue_delete_expired

* *Mode*: write
* *Arguments*:
* *Returns*: `void`

Delete all expired messages.  This is a maintenance task that should occur
about once an hour.


### azure_queue_get

* *Mode*: write
* *Arguments*:
  * `queue_name text`
  * `visible timestamp`
  * `count integer`
* *Returns*: `table`
  * `message_id uuid`
  * `message_text text`
  * `pop_receipt uuid`

Get up to `count` messages from the given queue, setting the `visible`
column of each to the given value.  Returns a `message_id` and
`pop_receipt` for each one, for use with `azure_queue_delete` and
`azure_queue_update`.


### azure_queue_put

* *Mode*: write
* *Arguments*:
  * `queue_name text`
  * `message_text text`
  * `visible timestamp`
  * `expires timestamp`
* *Returns*: `void`

Put the given message into the given queue.  The message will not be visible until
after the visible timestamp, and will disappear after the expires timestamp.


### azure_queue_update

* *Mode*: write
* *Arguments*:
  * `queue_name text`
  * `message_text text`
  * `message_id uuid`
  * `pop_receipt uuid`
  * `visible timestamp`
* *Returns*: `void`

Update the message identified by the given `queue_name`, `message_id` and
`pop_receipt`, setting its `visible` and `message_text` properties as
given.


### cancel_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `reason text`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`

If the current run is pending or running, mark it as exception with the given
reason.  If the task is unscheduled, a run with that status is
created to represent the cancellation.  This returns the task's updated
status, or nothing if the current status was not as expected.

### check_task_claim

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `run_id int`
  * `taken_until_in timestamptz`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`

Check the given task for a claim on the given run expiring at the given
time.  If the run is still running, it is marked as claim-expired and
a retry scheduled (if retries_left).  

This returns the task's updated status, or nothing if the current status
was not as expected.

### claim_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `run_id int`
  * `worker_group text`
  * `worker_id text`
  * `hint_id text`
  * `taken_until_in timestamptz`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`

Claim the given run of the given task for the given worker.  The hint is recorded in the run,
for comparison when the claim expires.  This returns the task's updated
status, or nothing if the current status was not as expected.

### create_queue_artifact

* *Mode*: write
* *Arguments*:
  * `task_id_in text`
  * `run_id_in integer`
  * `name_in text`
  * `storage_type_in text`
  * `content_type_in text`
  * `details_in jsonb`
  * `present_in boolean`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `task_id text`
  * `run_id integer`
  * `name text`
  * `storage_type text`
  * `content_type text`
  * `details jsonb`
  * `present boolean`
  * `expires timestamptz`

Create a new artifact. Raises UNIQUE_VIOLATION if the artifact already exists.
Returns the newly created artifact.

### create_queue_provisioner

* *Mode*: write
* *Arguments*:
  * `provisioner_id_in text`
  * `expires_in timestamptz`
  * `last_date_active_in timestamptz`
  * `description_in text`
  * `stability_in text`
  * `actions_in jsonb`
* *Returns*: `uuid`

Create a new queue provisioner.  Raises UNIQUE_VIOLATION if the provisioner already exists.

### create_queue_worker

* *Mode*: write
* *Arguments*:
  * `provisioner_id_in text`
  * `worker_type_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `quarantine_until_in timestamptz`
  * `expires_in timestamptz`
  * `first_claim_in timestamptz`
  * `recent_tasks_in jsonb`
* *Returns*: `uuid`

Create a new queue worker.  Raises UNIQUE_VIOLATION if the worker already exists.

### create_queue_worker_type

* *Mode*: write
* *Arguments*:
  * `provisioner_id_in text`
  * `worker_type_in text`
  * `expires_in timestamptz`
  * `last_date_active_in timestamptz`
  * `description_in text`
  * `stability_in text`
* *Returns*: `uuid`

Create a new queue worker type.  Raises UNIQUE_VIOLATION if the worker type already exists.

### create_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `provisioner_id text`
  * `worker_type text`
  * `scheduler_id text`
  * `task_group_id text`
  * `dependencies jsonb`
  * `requires task_requires`
  * `routes jsonb`
  * `priority task_priority`
  * `retries integer`
  * `created timestamptz`
  * `deadline timestamptz`
  * `expires timestamptz`
  * `scopes jsonb`
  * `payload jsonb`
  * `metadata jsonb`
  * `tags jsonb`
  * `extra jsonb`
* *Returns*: `void`

Create a new task, without scheduling it, and with empty values
for the status information.

### delete_queue_artifact

* *Mode*: write
* *Arguments*:
  * `task_id_in text`
  * `run_id_in integer`
  * `name_in text`
* *Returns*: `void`

Delete a queue artifact.

### delete_queue_provisioner

* *Mode*: write
* *Arguments*:
  * `provisioner_id text`
  * `stability text`
  * `description text`
* *Returns*: `void`

Delete a queue provisioner.

### delete_queue_worker_type

* *Mode*: write
* *Arguments*:
  * `provisioner_id text`
  * `worker_type text`
  * `stability text`
  * `description text`
* *Returns*: `void`

Delete a queue worker type.

### ensure_task_group

* *Mode*: write
* *Arguments*:
  * `task_group_id_in text`
  * `scheduler_id_in text`
  * `expires_in timestamptz`
* *Returns*: `void`

Ensure that the given task group exists, has the matching scheduler_id,
and has an expiration greater than the given expiration.  Expiration is
bumped by an hour at a time to avoid unnecessary updates.  This returns
23505 (UNIQUE_VIOLATION) when the group exists with a different
scheduler_id.

### expire_queue_provisioners

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`

Expire provisioners that come before `expires_in`.
Returns a count of rows that have been deleted.

### expire_queue_worker_types

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`

Expire queue worker types that come before `expires_in`.
Returns a count of rows that have been deleted.

### expire_queue_workers

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`

Expire non-quarantined queue workers that come before `expires_in`.
Returns a count of rows that have been deleted.

### expire_task_dependencies

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`

Delete task dependencies with expiration dates before `expires_in`.
Returns a count of rows that have been deleted.

### expire_task_groups

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`

Delete task groups with expiration dates before `expires_in`.
Returns a count of rows that have been deleted.

### expire_tasks

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`

Delete tasks with expiration dates before `expires_in`.
Returns a count of rows that have been deleted.

### get_dependent_tasks

* *Mode*: read
* *Arguments*:
  * `required_task_id_in text`
  * `satisfied_in boolean`
  * `tasks_after_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `dependent_task_id text`
  * `requires task_requires`
  * `satisfied boolean`

Get the un-expired tasks that depend on this one, limiting to only (un)satisfied
dependencies if `satisfied_in` is not null.

Only dependencies with `dependent_task_id > tasks_after_in` are returned.
This supports paginated queries that are not susceptible to rows being
added or removed.  Typically only one of `page_offset_in` and
`tasks_after_in` are non-null.

### get_queue_artifact

* *Mode*: read
* *Arguments*:
  * `task_id_in text`
  * `run_id_in integer`
  * `name_in text`
* *Returns*: `table`
  * `task_id text`
  * `run_id integer`
  * `name text`
  * `storage_type text`
  * `content_type text`
  * `details jsonb`
  * `present boolean`
  * `expires timestamptz`

Get a queue artifact. The returned table will have one or zero row.

### get_queue_artifacts

* *Mode*: read
* *Arguments*:
  * `task_id_in text`
  * `run_id_in integer`
  * `expires_in timestamptz`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `task_id text`
  * `run_id integer`
  * `name text`
  * `storage_type text`
  * `content_type text`
  * `details jsonb`
  * `present boolean`
  * `expires timestamptz`

Get existing queue artifacts filtered by the optional arguments,
ordered by the `task_id`, `run_id`, and `name`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_queue_provisioner

* *Mode*: read
* *Arguments*:
  * `provisioner_id_in text`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `provisioner_id text`
  * `expires timestamptz`
  * `last_date_active timestamptz`
  * `description text`
  * `stability text`
  * `actions jsonb`
  * `etag uuid`

Get a queue provisioner by provisioner_id.

### get_queue_provisioners

* *Mode*: read
* *Arguments*:
  * `expires_in timestamptz`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `provisioner_id text`
  * `expires timestamptz`
  * `last_date_active timestamptz`
  * `description text`
  * `stability text`
  * `actions jsonb`
  * `etag uuid`

Get queue provisioners ordered by `provisioner_id`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_queue_worker

* *Mode*: read
* *Arguments*:
  * `provisioner_id_in text`
  * `worker_type_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `provisioner_id text`
  * `worker_type text`
  * `worker_group text`
  * `worker_id text`
  * `quarantine_until timestamptz`
  * `expires timestamptz`
  * `first_claim timestamptz`
  * `recent_tasks jsonb`
  * `etag uuid`

Get a non-expired queue worker by provisioner_id, worker_type, worker_group, and worker_id.
Workers are not considered expired until after their quarantine date expires.

### get_queue_worker_type

* *Mode*: read
* *Arguments*:
  * `provisioner_id_in text`
  * `worker_type_in text`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `provisioner_id text`
  * `worker_type text`
  * `expires timestamptz`
  * `last_date_active timestamptz`
  * `description text`
  * `stability text`
  * `etag uuid`

Get a non-expired queue worker type by provisioner_id and worker_type.

### get_queue_worker_types

* *Mode*: read
* *Arguments*:
  * `provisioner_id_in text`
  * `worker_type_in text`
  * `expires_in timestamptz`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `provisioner_id text`
  * `worker_type text`
  * `expires timestamptz`
  * `last_date_active timestamptz`
  * `description text`
  * `stability text`
  * `etag uuid`

Get queue worker types ordered by `provisioner_id` and `worker_type`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_queue_workers

* *Mode*: read
* *Arguments*:
  * `provisioner_id_in text`
  * `worker_type_in text`
  * `expires_in timestamptz`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `provisioner_id text`
  * `worker_type text`
  * `worker_group text`
  * `worker_id text`
  * `quarantine_until timestamptz`
  * `expires timestamptz`
  * `first_claim timestamptz`
  * `recent_tasks jsonb`
  * `etag uuid`

Get non-expired queue workers ordered by provisioner_id, worker_type, worker_group, and worker_id.
Workers are not considered expired until after their quarantine date expires.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_task

* *Mode*: read
* *Arguments*:
  * `task_id_in text`
* *Returns*: `table`
  * `   task_id text`
  * `  provisioner_id text`
  * `  worker_type text`
  * `  scheduler_id text`
  * `  task_group_id text`
  * `  dependencies jsonb`
  * `  requires task_requires`
  * `  routes jsonb`
  * `  priority task_priority`
  * `  retries integer`
  * `  retries_left int`
  * `  created timestamptz`
  * `  deadline timestamptz`
  * `  expires timestamptz`
  * `  scopes jsonb`
  * `  payload jsonb`
  * `  metadata jsonb`
  * `  tags jsonb`
  * `  extra jsonb`
  * `  runs jsonb`
  * `  taken_until timestamptz `

Get all properties of a task.  Note that all properties but `runs`,
`retries_left`, and `taken_until` are immutable.

### get_task_group

* *Mode*: read
* *Arguments*:
  * `task_group_id_in text`
* *Returns*: `table`
  * `   task_group_id text`
  * `  scheduler_id text`
  * `  expires timestamptz `

Get a task group.

### get_tasks_by_task_group

* *Mode*: read
* *Arguments*:
  * `task_group_id_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `   task_id text`
  * `  provisioner_id text`
  * `  worker_type text`
  * `  scheduler_id text`
  * `  task_group_id text`
  * `  dependencies jsonb`
  * `  requires task_requires`
  * `  routes jsonb`
  * `  priority task_priority`
  * `  retries integer`
  * `  retries_left int`
  * `  created timestamptz`
  * `  deadline timestamptz`
  * `  expires timestamptz`
  * `  scopes jsonb`
  * `  payload jsonb`
  * `  metadata jsonb`
  * `  tags jsonb`
  * `  extra jsonb`
  * `  runs jsonb`
  * `  taken_until timestamptz `

Get all properties of all tasks in the given task group.

### is_task_blocked

* *Mode*: read
* *Arguments*:
  * `dependent_task_id_in text`
* *Returns*: `boolean`

Return true if the task has remaining un-satisfied dependencies.

### is_task_group_active

* *Mode*: read
* *Arguments*:
  * `task_group_id_in text`
* *Returns*: `boolean`

temp, removed in next commit

### mark_task_ever_resolved

* *Mode*: write
* *Arguments*:
  * `task_id_in text`
* *Returns*: `void`

temp, removed in next commit

### reclaim_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `run_id int`
  * `taken_until_in timestamptz`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`

Relaim the given run of the given task run, until the new taken_until time.
This returns the task's updated status, or nothing if the current status was not as expected.

### remove_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
* *Returns*: `void`

Remove the given task, regardless of its expiration status.  This is
typically used when task creation has failed.

### remove_task_dependency

* *Mode*: write
* *Arguments*:
  * `dependent_task_id_in text`
  * `required_task_id_in text`
* *Returns*: `void`

Mark the given dependency as satisfied.  If the dependency does not exist, nothing
happens.

### rerun_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`

Ensure that no run is currently running or pending, and then create a new
pending run with the given reason.  This also resets the retries_left
column to `retries` (unless the sanity-check maximum runs has been
reached).  This returns the task's updated status, or nothing if the
current status was not as expected.

### resolve_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `run_id int`
  * `state text`
  * `reason text`
  * `retry_reason text`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`

Resolve the given run with the given state and reason, setting
run.resolved and resetting `taken_until`.  If `retry_reason` is not null
and there are `retries_left`, a new pending run is added, and
`retries_left` is decremented.  This returns the task's updated status,
or nothing if the current status was not as expected.

### resolve_task_at_deadline

* *Mode*: write
* *Arguments*:
  * `task_id text`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`

The given task has reached its deadline, so mark it as resolved, adding a
run if necessary.  This returns the task's updated status, or nothing if
the current status was not as expected.

### satisfy_task_dependency

* *Mode*: write
* *Arguments*:
  * `dependent_task_id_in text`
  * `required_task_id_in text`
* *Returns*: `void`

Mark the given dependency as satisfied.  If the dependency does not exist, nothing
happens.

### schedule_task

* *Mode*: write
* *Arguments*:
  * `task_id text`
  * `reason_created text`
* *Returns*: `table`
  * `retries_left integer`
  * `runs jsonb`
  * `taken_until timestamptz`

Schedule the initial run for a task, moving the task from "unscheduled" to "pending".
This returns the task's updated status, or nothing if the current status was not
as expected.

### update_queue_artifact

* *Mode*: write
* *Arguments*:
  * `task_id_in text`
  * `run_id_in integer`
  * `name_in text`
  * `details_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `table`
  * `task_id text`
  * `run_id integer`
  * `name text`
  * `storage_type text`
  * `content_type text`
  * `details jsonb`
  * `present boolean`
  * `expires timestamptz`

Update a queue artifact.
Returns the up-to-date artifact row that have the same task id, run id, and name.

### update_queue_provisioner

* *Mode*: write
* *Arguments*:
  * `provisioner_id_in text`
  * `expires_in timestamptz`
  * `last_date_active_in timestamptz`
  * `description_in text`
  * `stability_in text`
  * `actions_in jsonb`
* *Returns*: `table`
  * `provisioner_id text`
  * `expires timestamptz`
  * `last_date_active timestamptz`
  * `description text`
  * `stability text`
  * `actions jsonb`
  * `etag uuid`

Update a queue provisioner's expires, last_date_active, description, stability, and actions.
All parameters must be supplied.

### update_queue_worker

* *Mode*: write
* *Arguments*:
  * `provisioner_id_in text`
  * `worker_type_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `quarantine_until_in timestamptz`
  * `expires_in timestamptz`
  * `recent_tasks_in jsonb`
* *Returns*: `table`
  * `provisioner_id text`
  * `worker_type text`
  * `worker_group text`
  * `worker_id text`
  * `quarantine_until timestamptz`
  * `expires timestamptz`
  * `first_claim timestamptz`
  * `recent_tasks jsonb`
  * `etag uuid`

Update a queue worker's quarantine_until, expires, and recent_tasks.
All parameters must be supplied.

### update_queue_worker_type

* *Mode*: write
* *Arguments*:
  * `provisioner_id_in text`
  * `worker_type_in text`
  * `expires_in timestamptz`
  * `last_date_active_in timestamptz`
  * `description_in text`
  * `stability_in text`
* *Returns*: `table`
  * `provisioner_id text`
  * `worker_type text`
  * `expires timestamptz`
  * `last_date_active timestamptz`
  * `description text`
  * `stability text`
  * `etag uuid`

Update a queue worker type's expires, last_date_active, description, and stability.
All parameters must be supplied.

### deprecated methods

* `queue_provisioner_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `queue_provisioner_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `queue_provisioner_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `queue_provisioner_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `queue_provisioner_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)
* `queue_worker_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `queue_worker_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `queue_worker_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `queue_worker_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `queue_worker_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)
* `queue_worker_type_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `queue_worker_type_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `queue_worker_type_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `queue_worker_type_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `queue_worker_type_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)

## secrets

* [`delete_secret`](#delete_secret)
* [`expire_secrets`](#expire_secrets)
* [`get_secret`](#get_secret)
* [`get_secrets`](#get_secrets)
* [`upsert_secret`](#upsert_secret)

### delete_secret

* *Mode*: write
* *Arguments*:
  * `name_in text`
* *Returns*: `void`

Delete a secret entirely

### expire_secrets

* *Mode*: write
* *Arguments*:
* *Returns*: `integer`

Delete all secrets with an 'expires' in the past.

### get_secret

* *Mode*: read
* *Arguments*:
  * `name_in text`
* *Returns*: `table`
  * `name text`
  * `encrypted_secret jsonb`
  * `expires timestamptz`

Get a single secret (including secret content and expiration)

### get_secrets

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `name text`

Get many secrets at once. This only includes names.
Fetch an individual secret to get the contents

### upsert_secret

* *Mode*: write
* *Arguments*:
  * `name_in text`
  * `encrypted_secret_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `void`

Store an encrypted secret whether it is new or being updated

### deprecated methods

* `secrets_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `secrets_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `secrets_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `secrets_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `secrets_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)

## web_server

* [`add_github_access_token`](#add_github_access_token)
* [`create_access_token`](#create_access_token)
* [`create_authorization_code`](#create_authorization_code)
* [`expire_access_tokens`](#expire_access_tokens)
* [`expire_authorization_codes`](#expire_authorization_codes)
* [`expire_sessions`](#expire_sessions)
* [`get_access_token`](#get_access_token)
* [`get_authorization_code`](#get_authorization_code)
* [`load_github_access_token`](#load_github_access_token)
* [`session_add`](#session_add)
* [`session_load`](#session_load)
* [`session_remove`](#session_remove)
* [`session_touch`](#session_touch)

### add_github_access_token

* *Mode*: write
* *Arguments*:
  * `user_id_in text`
  * `encrypted_access_token_in jsonb`
* *Returns*: `void`

Sets the encrypted access token for `user_id_in` to
`encrypted_access_token_in`.

If no access token is currently set for `user_id_in`, a new row is
inserted, otherwise the existing row's encrypted access token is updated
to `encrypted_access_token_in`.

### create_access_token

* *Mode*: write
* *Arguments*:
  * `hashed_access_token_in text`
  * `encrypted_access_token_in jsonb`
  * `client_id_in text`
  * `redirect_uri_in text`
  * `identity_in text`
  * `identity_provider_id_in text`
  * `expires_in timestamptz`
  * `client_details_in jsonb`
* *Returns*: `table`
  * `hashed_access_token text`
  * `encrypted_access_token jsonb`
  * `client_id text`
  * `redirect_uri text`
  * `identity text`
  * `identity_provider_id text`
  * `expires timestamptz`
  * `client_details jsonb`

Create an access token entry.

### create_authorization_code

* *Mode*: write
* *Arguments*:
  * `code_in text`
  * `client_id_in text`
  * `redirect_uri_in text`
  * `identity_in text`
  * `identity_provider_id_in text`
  * `expires_in timestamptz`
  * `client_details_in jsonb`
* *Returns*: `table`
  * `code text`
  * `client_id text`
  * `redirect_uri text`
  * `identity text`
  * `identity_provider_id text`
  * `expires timestamptz`
  * `client_details jsonb`

Create an authorization code.

### expire_access_tokens

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`

Delete access token entries that expireq before the current time.
Returns a count of rows that have been deleted.

### expire_authorization_codes

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`

Delete authorization codes that expire before `expires_in`.
Returns a count of rows that have been deleted.

### expire_sessions

* *Mode*: write
* *Arguments*:
* *Returns*: `integer`

Delete sessions that expire before the current time.
Returns a count of rows that have been deleted.

### get_access_token

* *Mode*: read
* *Arguments*:
  * `hashed_access_token_in text`
* *Returns*: `table`
  * `hashed_access_token text`
  * `encrypted_access_token jsonb`
  * `client_id text`
  * `redirect_uri text`
  * `identity text`
  * `identity_provider_id text`
  * `expires timestamptz`
  * `client_details jsonb`

Get an access token entry.

### get_authorization_code

* *Mode*: read
* *Arguments*:
  * `code_in text`
* *Returns*: `table`
  * `code text`
  * `client_id text`
  * `redirect_uri text`
  * `identity text`
  * `identity_provider_id text`
  * `expires timestamptz`
  * `client_details jsonb`

Get an authorization code entry given a code.

### load_github_access_token

* *Mode*: read
* *Arguments*:
  * `user_id_in text`
* *Returns*: `table`
  * `encrypted_access_token jsonb`

Returns the encrypted github access token for a given user.

### session_add

* *Mode*: write
* *Arguments*:
  * `hashed_session_id_in text`
  * `encrypted_session_id_in jsonb`
  * `data_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `void`

Set a session.

If no session exists with hashed session id `hashed_session_id_in`,
a new row is inserted, otherwise the existing session's data is replaced
with the data in `data_in`.

### session_load

* *Mode*: read
* *Arguments*:
  * `hashed_session_id_in text`
* *Returns*: `table`
  * `hashed_session_id text`
  * `encrypted_session_id jsonb`
  * `data jsonb`
  * `expires timestamptz`

Returns the session for a given hashed session id.

### session_remove

* *Mode*: write
* *Arguments*:
  * `hashed_session_id_in text`
* *Returns*: `void`

Removes a web session

### session_touch

* *Mode*: write
* *Arguments*:
  * `hashed_session_id_in text`
  * `data_in jsonb`
  * `expires_in timestamptz`
* *Returns*: `void`

Touch a given session given a hashed session id and session `data`.
If the hashed session id does not exist, then an error code `P0002` will be thrown.

### deprecated methods

* `access_token_table_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `access_token_table_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `access_token_table_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `access_token_table_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `access_token_table_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)
* `authorization_codes_table_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `authorization_codes_table_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `authorization_codes_table_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `authorization_codes_table_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `authorization_codes_table_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)
* `session_storage_table_entities_create(pk text, rk text, properties jsonb, overwrite boolean, version integer)` (compatibility guaranteed until v37.0.0)
* `session_storage_table_entities_load(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `session_storage_table_entities_modify(partition_key text, row_key text, properties jsonb, version integer, old_etag uuid)` (compatibility guaranteed until v37.0.0)
* `session_storage_table_entities_remove(partition_key text, row_key text)` (compatibility guaranteed until v37.0.0)
* `session_storage_table_entities_scan(pk text, rk text, condition text, size integer, page integer)` (compatibility guaranteed until v37.0.0)

## worker_manager

* [`create_worker`](#create_worker)
* [`create_worker_pool`](#create_worker_pool)
* [`create_worker_pool_error`](#create_worker_pool_error)
* [`delete_worker`](#delete_worker)
* [`delete_worker_pool`](#delete_worker_pool)
* [`delete_worker_pool_error`](#delete_worker_pool_error)
* [`expire_worker_pool_errors`](#expire_worker_pool_errors)
* [`expire_worker_pools`](#expire_worker_pools)
* [`expire_workers`](#expire_workers)
* [`get_worker_2`](#get_worker_2)
* [`get_worker_pool_error`](#get_worker_pool_error)
* [`get_worker_pool_errors_for_worker_pool`](#get_worker_pool_errors_for_worker_pool)
* [`get_worker_pool_with_capacity`](#get_worker_pool_with_capacity)
* [`get_worker_pools_with_capacity`](#get_worker_pools_with_capacity)
* [`get_workers`](#get_workers)
* [`remove_worker_pool_previous_provider_id`](#remove_worker_pool_previous_provider_id)
* [`update_worker_2`](#update_worker_2)
* [`update_worker_pool_provider_data`](#update_worker_pool_provider_data)
* [`update_worker_pool_with_capacity`](#update_worker_pool_with_capacity)

### create_worker

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `provider_id_in text`
  * `created_in timestamptz`
  * `expires_in timestamptz`
  * `state_in text`
  * `provider_data_in jsonb`
  * `capacity_in integer`
  * `last_modified_in timestamptz`
  * `last_checked_in timestamptz`
* *Returns*: `uuid`

Create a new worker. Raises UNIQUE_VIOLATION if the worker already exists.
Returns the etag of the newly created worker.

### create_worker_pool

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `provider_id_in text`
  * `previous_provider_ids_in jsonb`
  * `description_in text`
  * `config_in jsonb`
  * `created_in timestamptz`
  * `last_modified_in timestamptz`
  * `owner_in text`
  * `email_on_error_in boolean`
  * `provider_data_in jsonb`
* *Returns*: `void`

Create a new worker pool.  Raises UNIQUE_VIOLATION if the pool already exists.

### create_worker_pool_error

* *Mode*: write
* *Arguments*:
  * `error_id_in text`
  * `worker_pool_id_in text`
  * `reported_in timestamptz`
  * `kind_in text`
  * `title_in text`
  * `description_in text`
  * `extra_in jsonb`
* *Returns*: `uuid`

Create a new worker pool error.  Raises UNIQUE_VIOLATION if the error already exists.

### delete_worker

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
* *Returns*: `void`

Delete a worker.

### delete_worker_pool

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
* *Returns*: `void`

Delete a worker pool immediately.

### delete_worker_pool_error

* *Mode*: write
* *Arguments*:
  * `error_id_in text`
  * `worker_pool_id_in text`
* *Returns*: `void`

Delete a worker pool error immediately.

### expire_worker_pool_errors

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`

Expire worker pool errors reported before `expires_in`.
Returns a count of rows that have been deleted.

### expire_worker_pools

* *Mode*: write
* *Arguments*:
* *Returns*: `table`
  * `worker_pool_id text`

Expire worker pools, deleting those which have provider-id null-provider and
no previous_provider_ids.  Returns the worker pool ids that it deletes.

### expire_workers

* *Mode*: write
* *Arguments*:
  * `expires_in timestamptz`
* *Returns*: `integer`

Expire workers that come before `expires_in`.
Returns a count of rows that have been deleted.

### get_worker_2

* *Mode*: read
* *Arguments*:
  * `worker_pool_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
* *Returns*: `table`
  * `worker_pool_id text`
  * `worker_group text`
  * `worker_id text`
  * `provider_id text`
  * `created timestamptz`
  * `expires timestamptz`
  * `state text`
  * `provider_data jsonb`
  * `capacity integer`
  * `last_modified timestamptz`
  * `last_checked timestamptz`
  * `secret jsonb`
  * `etag uuid`

Get an existing worker. The returned table will have one or (if no such worker is defined) zero rows.

### get_worker_pool_error

* *Mode*: read
* *Arguments*:
  * `error_id_in text`
  * `worker_pool_id_in text`
* *Returns*: `table`
  * `error_id text`
  * `worker_pool_id text`
  * `reported timestamptz`
  * `kind text`
  * `title text`
  * `description text`
  * `extra jsonb`

Get an existing worker pool error.  The returned table will have one or (if no such worker pool error is defined) zero rows.

### get_worker_pool_errors_for_worker_pool

* *Mode*: read
* *Arguments*:
  * `error_id_in text`
  * `worker_pool_id_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `error_id text`
  * `worker_pool_id text`
  * `reported timestamptz`
  * `kind text`
  * `title text`
  * `description text`
  * `extra jsonb`

Get existing worker pool errors filtered by `worker_pool_id` and `error_id`,
ordered by `reported`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_worker_pool_with_capacity

* *Mode*: read
* *Arguments*:
  * `worker_pool_id_in text`
* *Returns*: `table`
  * `worker_pool_id text`
  * `provider_id text`
  * `previous_provider_ids jsonb`
  * `description text`
  * `config jsonb`
  * `created timestamptz`
  * `last_modified timestamptz`
  * `owner text`
  * `email_on_error boolean`
  * `provider_data jsonb`
  * `current_capacity integer`

Get an existing worker pool.  The returned table will have one or (if no such worker pool is defined) zero rows.

### get_worker_pools_with_capacity

* *Mode*: read
* *Arguments*:
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `worker_pool_id text`
  * `provider_id text`
  * `previous_provider_ids jsonb`
  * `description text`
  * `config jsonb`
  * `created timestamptz`
  * `last_modified timestamptz`
  * `owner text`
  * `email_on_error boolean`
  * `provider_data jsonb`
  * `current_capacity integer`

Get existing worker pools, ordered by `worker_pool_id`.  If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### get_workers

* *Mode*: read
* *Arguments*:
  * `worker_pool_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `state_in text`
  * `page_size_in integer`
  * `page_offset_in integer`
* *Returns*: `table`
  * `worker_pool_id text`
  * `worker_group text`
  * `worker_id text`
  * `provider_id text`
  * `created timestamptz`
  * `expires timestamptz`
  * `state text`
  * `provider_data jsonb`
  * `capacity integer`
  * `last_modified timestamptz`
  * `last_checked timestamptz`

Get existing workers filtered by the optional arguments,
ordered by `worker_pool_id`, `worker_group`, and  `worker_id`.
If the pagination arguments are both NULL, all rows are returned.
Otherwise, page_size rows are returned at offset page_offset.

### remove_worker_pool_previous_provider_id

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `provider_id_in text`
* *Returns*: `void`

Remove the given provider_id from the worker pool's previous_provider_ids.  It is
not an error if the worker pool does not exist, or if the provider_id is not in the
previous_provider_ids set.

### update_worker_2

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `worker_group_in text`
  * `worker_id_in text`
  * `provider_id_in text`
  * `created_in timestamptz`
  * `expires_in timestamptz`
  * `state_in text`
  * `provider_data_in jsonb`
  * `capacity_in integer`
  * `last_modified_in timestamptz`
  * `last_checked_in timestamptz`
  * `etag_in uuid`
  * `secret_in jsonb`
* *Returns*: `table`
  * `worker_pool_id text`
  * `worker_group text`
  * `worker_id text`
  * `provider_id text`
  * `created timestamptz`
  * `expires timestamptz`
  * `state text`
  * `provider_data jsonb`
  * `capacity integer`
  * `last_modified timestamptz`
  * `last_checked timestamptz`
  * `etag uuid`
  * `secret jsonb`

Update a worker.
Returns the up-to-date worker row that have the same worker_pool_id, worker_group, and worker_id.
If the etag argument is empty then the update will overwrite the matched row.
Else, the function will fail if the etag is out of date. This is useful for concurency handling.

### update_worker_pool_provider_data

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `provider_id_in text`
  * `provider_data_in jsonb`
* *Returns*: `void`

Update the provider_data for the given provider_id in this worker pool.  Note that
this sets the provider_data property unconditionally, and it is up to the service
to ensure that concurrent modifications do not occur.  It is not an error if the
worker pool does not exist.

### update_worker_pool_with_capacity

* *Mode*: write
* *Arguments*:
  * `worker_pool_id_in text`
  * `provider_id_in text`
  * `description_in text`
  * `config_in jsonb`
  * `last_modified_in timestamptz`
  * `owner_in text`
  * `email_on_error_in boolean`
* *Returns*: `table`
  * `worker_pool_id text`
  * `provider_id text`
  * `description text`
  * `config jsonb`
  * `created timestamptz`
  * `last_modified timestamptz`
  * `owner text`
  * `email_on_error boolean`
  * `previous_provider_id text`
  * `current_capacity integer`

Update API-accessible columns on an existig worker pool.  All fields are
overridden, but if the provider_id changes, then the existing provider_id
is added to previous_provider_ids.  The return value contains values
required for an API response and previous_provider_id (singular) containing
the provider_id found before the update.  If no such worker pool exists,
the return value is an empty set.
